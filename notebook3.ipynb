{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import fitz  # PyMuPDF\n",
    "import io\n",
    "import pdfplumber\n",
    "import json\n",
    "\n",
    "\n",
    "def display_first_two_pdf_pages(pdf_bytes):\n",
    "    # Load the PDF file from bytes\n",
    "    pdf = fitz.open(\"pdf\", pdf_bytes)\n",
    "    num_pages = len(pdf)\n",
    "\n",
    "    # Create a two-column layout if there are at least two pages, otherwise one column\n",
    "    if num_pages >= 2:\n",
    "        cols = st.columns(2)\n",
    "    else:\n",
    "        cols = st.columns(1)\n",
    "\n",
    "    # Display the first page\n",
    "    page = pdf.load_page(0)\n",
    "    pix = page.get_pixmap()\n",
    "    img_data = pix.tobytes(\"ppm\")\n",
    "    image = io.BytesIO(img_data)\n",
    "    with cols[0]:\n",
    "        st.image(image, caption=\"First page of the PDF\", use_column_width=True)\n",
    "\n",
    "    # Display the second page if it exists\n",
    "    if num_pages >= 2:\n",
    "        page = pdf.load_page(1)\n",
    "        pix = page.get_pixmap()\n",
    "        img_data = pix.tobytes(\"ppm\")\n",
    "        image = io.BytesIO(img_data)\n",
    "        with cols[1]:\n",
    "            st.image(image, caption=\"Second page of the PDF\", use_column_width=True)\n",
    "\n",
    "    # Close the PDF file\n",
    "    pdf.close()\n",
    "\n",
    "\n",
    "def extract_pdf_text(pdf_path):\n",
    "    # Open the PDF file\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        # Initialize an empty list to store the extracted data\n",
    "        data = []\n",
    "        # Iterate through each page\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            # Extract the text with bounding boxes\n",
    "            for element in page.extract_words():\n",
    "                text = element[\"text\"]\n",
    "                x0, y0, x1, y1 = (\n",
    "                    element[\"x0\"],\n",
    "                    element[\"top\"],\n",
    "                    element[\"x1\"],\n",
    "                    element[\"bottom\"],\n",
    "                )\n",
    "                data.append([page_num + 1, text, x0, y0, x1, y1])\n",
    "\n",
    "        # Convert the list to a DataFrame\n",
    "        df = pd.DataFrame(data, columns=[\"page\", \"text\", \"x0\", \"y0\", \"x1\", \"y1\"])\n",
    "        return df\n",
    "\n",
    "\n",
    "def find_interval(number, intervals):\n",
    "    intervals = sorted(intervals)\n",
    "    for interval in intervals:\n",
    "        if number >= interval[0] and number < interval[1]:\n",
    "            return interval\n",
    "    return None\n",
    "\n",
    "\n",
    "def assign_intervals_and_values(df, gridlines):\n",
    "    # Create a list of intervals from the gridlines\n",
    "    intervals = [item[\"interval\"] for item in gridlines]\n",
    "    df[\"interval\"] = df[\"x0\"].apply(lambda x: find_interval(x, intervals))\n",
    "    df[\"value\"] = df[\"interval\"].apply(\n",
    "        lambda x: (\n",
    "            next((item[\"label\"] for item in gridlines if item[\"interval\"] == x), None)\n",
    "            if x\n",
    "            else None\n",
    "        )\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_consecutive_values(df, target_value):\n",
    "    processed_rows = []\n",
    "    current_row = None\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if row[\"value\"] == target_value:\n",
    "            if current_row is None:\n",
    "                current_row = row.copy()\n",
    "            else:\n",
    "                # Concatenate the text field\n",
    "                current_row[\"text\"] += row[\"text\"]\n",
    "                # Update the bounding box\n",
    "                current_row[\"x1\"] = max(current_row[\"x1\"], row[\"x1\"])\n",
    "                current_row[\"y1\"] = max(current_row[\"y1\"], row[\"y1\"])\n",
    "        else:\n",
    "            if current_row is not None:\n",
    "                processed_rows.append(current_row)\n",
    "                current_row = None\n",
    "            processed_rows.append(row)\n",
    "\n",
    "    if current_row is not None:\n",
    "        processed_rows.append(current_row)\n",
    "\n",
    "    df = pd.DataFrame(processed_rows)\n",
    "    df.dropna(subset=[\"value\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def concatenate_values(df):\n",
    "    new_value_column = []\n",
    "    new_text_column = []\n",
    "\n",
    "    # Iterate over the dataframe to concatenate values\n",
    "    current_value = None\n",
    "    current_text = \"\"\n",
    "\n",
    "    for value, text in zip(df[\"value\"], df[\"text\"]):\n",
    "        if value == current_value:\n",
    "            current_text += text + \" \"\n",
    "        else:\n",
    "            if current_value is not None:\n",
    "                new_value_column.append(current_value)\n",
    "                new_text_column.append(current_text.strip())\n",
    "            current_value = value\n",
    "            current_text = text + \" \"  # Added space at the end of each text\n",
    "\n",
    "    # Append the last accumulated values\n",
    "    if current_value is not None:\n",
    "        new_value_column.append(current_value)\n",
    "        new_text_column.append(current_text.strip())\n",
    "\n",
    "    # Create a new DataFrame with the concatenated values\n",
    "    new_df = pd.DataFrame({\"value\": new_value_column, \"text\": new_text_column})\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def transform_df(new_df, unique_identifier, date_format):\n",
    "    # new_df[unique_identifier] = new_df.apply(\n",
    "    #     lambda x: x.text if x.value == unique_identifier else None, axis=1\n",
    "    # ).ffill()\n",
    "    # new_df = new_df.pivot_table(\n",
    "    #     index=unique_identifier, columns=\"value\", values=\"text\", aggfunc=\"first\"\n",
    "    # )\n",
    "    # new_df.reset_index(drop=True, inplace=True)\n",
    "    new_df[\"reg\"] = new_df[\"reg\"].str.replace(\" \", \"\")\n",
    "\n",
    "    # Filter rows where \"reg\" column matches the specified pattern\n",
    "    new_df = new_df[\n",
    "        new_df[\"reg\"].str.contains(r\"^(?:[A-Z]+[0-9]|[0-9]+[A-Z])[A-Z0-9]*$\", na=False)\n",
    "    ]\n",
    "    if date_format is not None:\n",
    "        if \"date_from\" in new_df.columns:\n",
    "            new_df[\"date_from\"] = pd.to_datetime(\n",
    "                new_df[\"date_from\"], format=date_format, errors=\"coerce\"\n",
    "            ).dt.strftime(\"%d/%m/%Y\")\n",
    "        if \"date_to\" in new_df.columns:\n",
    "            new_df[\"date_to\"] = pd.to_datetime(\n",
    "                new_df[\"date_to\"], format=date_format, errors=\"coerce\"\n",
    "            ).dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    # Remove rows where date format does not match\n",
    "    if \"date_from\" in new_df.columns:\n",
    "        new_df = new_df[new_df[\"date_from\"].notna()]\n",
    "    if \"date_to\" in new_df.columns:\n",
    "        new_df = new_df[new_df[\"date_to\"].notna()]\n",
    "\n",
    "    # Select the required columns\n",
    "    columns_to_select = [\"reg\", \"make\", \"model\", \"date_from\", \"date_to\"]\n",
    "    existing_columns = [col for col in columns_to_select if col in new_df.columns]\n",
    "    new_df = new_df[existing_columns]\n",
    "    new_df = new_df.sort_values(by=\"reg\", ascending=True)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "council = \"East Lothian\"\n",
    "pdf_config = json.load(open(\"data_processor/data/pdf_config.json\"))\n",
    "\n",
    "gridlines = pdf_config[council][\"gridlines\"]\n",
    "unique_identifier = pdf_config[council][\"unique_identifier\"]\n",
    "date_format = pdf_config[council][\"date_format\"]\n",
    "pdf_path = f\"pdf_files/tabular/{council}.pdf\"\n",
    "\n",
    "\n",
    "df = extract_pdf_text(pdf_path)\n",
    "df = assign_intervals_and_values(df, gridlines)\n",
    "df = process_consecutive_values(df, target_value=unique_identifier)\n",
    "df_reduced = df[[\"text\", \"value\"]].reset_index(drop=True)\n",
    "# new_df = concatenate_values(df_reduced)\n",
    "# new_df = transform_df(new_df, unique_identifier, date_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_dataframe(df_reduced, unique_identifier):\n",
    "    # Initialize an empty list to store the dataframes\n",
    "    dataframes_list = []\n",
    "\n",
    "    # Find the indices where \"reference_number\" appears in the value column\n",
    "    reference_indices = df_reduced[df_reduced[\"value\"] == unique_identifier].index\n",
    "\n",
    "    # Iterate through the indices and create dataframes\n",
    "    for i in range(len(reference_indices)):\n",
    "        start_idx = reference_indices[i]\n",
    "        end_idx = reference_indices[i + 1] if i + 1 < len(reference_indices) else len(df_reduced)\n",
    "        chunk_df = df_reduced[start_idx:end_idx].reset_index(drop=True)\n",
    "        dataframes_list.append(chunk_df)\n",
    "\n",
    "    return dataframes_list\n",
    "\n",
    "dataframes_list = split_dataframe(df_reduced, unique_identifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframes(dataframes_list, unique_identifier):\n",
    "    new_dataframes_list = []\n",
    "\n",
    "    for df in dataframes_list:\n",
    "        df = df.groupby('value', as_index=False).agg({'text': ' '.join})\n",
    "        df[unique_identifier] = df[df[\"value\"] == unique_identifier][\"text\"].iloc[0]\n",
    "        df = df.pivot_table(\n",
    "                index=unique_identifier, columns=\"value\", values=\"text\", aggfunc=\"first\"\n",
    "            )\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "        new_dataframes_list.append(df)\n",
    "\n",
    "    new_df = pd.concat(new_dataframes_list)\n",
    "    return new_df\n",
    "\n",
    "new_df = process_dataframes(dataframes_list, unique_identifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>value</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supply me with</td>\n",
       "      <td>the following information?</td>\n",
       "      <td>canyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>registered as a</td>\n",
       "      <td>Taxi, Hackney Carriage</td>\n",
       "      <td>allvehicles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>November</td>\n",
       "      <td>2023 and 31st March</td>\n",
       "      <td>between22nd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vauxhall</td>\n",
       "      <td>Octavia S TDi</td>\n",
       "      <td>Council.GF16HJE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peugeot</td>\n",
       "      <td>Premier RS Blue HDI S/S</td>\n",
       "      <td>SD17OUF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Renault</td>\n",
       "      <td>Trafic</td>\n",
       "      <td>SK62UPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ford</td>\n",
       "      <td>Tourneo</td>\n",
       "      <td>MF68UYR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vauxhall East Lothian FOI Ref: 2024/ELF14849</td>\n",
       "      <td>Vivaro Council</td>\n",
       "      <td>LM68LXF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ford Pro Cab</td>\n",
       "      <td>Ford Pro Cab</td>\n",
       "      <td>SF68KLO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "value                                          make  \\\n",
       "0                                    supply me with   \n",
       "0                                               NaN   \n",
       "0                                   registered as a   \n",
       "0                                          November   \n",
       "0                                          Vauxhall   \n",
       "..                                              ...   \n",
       "0                                           Peugeot   \n",
       "0                                           Renault   \n",
       "0                                              Ford   \n",
       "0      Vauxhall East Lothian FOI Ref: 2024/ELF14849   \n",
       "0                                      Ford Pro Cab   \n",
       "\n",
       "value                       model              reg  \n",
       "0      the following information?           canyou  \n",
       "0                             NaN          number:  \n",
       "0          Taxi, Hackney Carriage      allvehicles  \n",
       "0             2023 and 31st March      between22nd  \n",
       "0                   Octavia S TDi  Council.GF16HJE  \n",
       "..                            ...              ...  \n",
       "0         Premier RS Blue HDI S/S          SD17OUF  \n",
       "0                          Trafic          SK62UPV  \n",
       "0                         Tourneo          MF68UYR  \n",
       "0                  Vivaro Council          LM68LXF  \n",
       "0                    Ford Pro Cab          SF68KLO  \n",
       "\n",
       "[228 rows x 3 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = transform_df(new_df, unique_identifier, date_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>value</th>\n",
       "      <th>reg</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YC71EBJ</td>\n",
       "      <td>Kia</td>\n",
       "      <td>MHEV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "value      reg make model\n",
       "0      YC71EBJ  Kia  MHEV"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[df_final[\"reg\"] == \"YC71EBJ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
